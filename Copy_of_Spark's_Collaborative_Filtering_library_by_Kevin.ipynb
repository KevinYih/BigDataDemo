{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinYih/BigDataDemo/blob/main/Copy_of_Spark's_Collaborative_Filtering_library_by_Kevin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPt5q27L5557"
      },
      "source": [
        "## Collaborative Filtering\n",
        "\n",
        "source: https://colab.research.google.com/drive/1UWeDiyXiwDDqe7ksN2kt-myHsuSLObv8?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0-YhEpP_Ds-"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsj5WYpR9QId"
      },
      "source": [
        "Let's set up Spark on your Colab environment.  Run the cell below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-qHai2252mI",
        "collapsed": true,
        "outputId": "4a51a902-4933-4d42-a609-8dd81e7ded6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=ae79f09049d963420f120860d99f649d3a42ffdd8135a7ff3ba1ecf55d64217c\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n",
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra fonts-nanum fonts-ipafont-gothic\n",
            "  fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 39.6 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 121925 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u412-ga-1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u412-ga-1~22.04.1) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u412-ga-1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u412-ga-1~22.04.1) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u412-ga-1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u412-ga-1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUUjUvXe3Sjk"
      },
      "source": [
        "Now we authenticate a Google Drive client to download the files we will be processing in our Spark job.\n",
        "\n",
        "**Make sure to follow the interactive instructions.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRElWs_x2mGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c37c28d-c87c-4da1-c298-e1994065fed1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        }
      ],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHsFTGUy2n1c"
      },
      "outputs": [],
      "source": [
        "id='1QtPy_HuIMSzhtYllT3-WeM3Sqg55wK_D'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('MovieLens.training')\n",
        "\n",
        "id='1ePqnsQTJRRvQcBoF2EhoPU8CU1i5byHK'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('MovieLens.test')\n",
        "\n",
        "id='1ncUBWdI5AIt3FDUJokbMqpHD2knd5ebp'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('MovieLens.item')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwtlO4_m_LbQ"
      },
      "source": [
        "If you executed the cells above, you should be able to see the dataset we will use for this Colab under the \"Files\" tab on the left panel.\n",
        "\n",
        "Next, we import some of the common libraries needed for our task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twk-K-jilWK7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtrJlMBt1Ela"
      },
      "source": [
        "Let's initialize the Spark context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vm3sAVeK1EDZ"
      },
      "outputs": [],
      "source": [
        "# create the session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "# create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAYRX2PMm0L6"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hXdMR6wnEIM"
      },
      "source": [
        "In this Colab, we will be using the [MovieLens dataset](https://grouplens.org/datasets/movielens/), specifically the 100K dataset (which contains in total 100,000 ratings from 1000 users on ~1700 movies).\n",
        "\n",
        "We load the ratings data in a 80%-20% ```training```/```test``` split, while the ```items``` dataframe contains the movie titles associated to the item identifiers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K93ABEy9Zlo"
      },
      "outputs": [],
      "source": [
        "schema_ratings = StructType([\n",
        "    StructField(\"user_id\", IntegerType(), False),\n",
        "    StructField(\"item_id\", IntegerType(), False),\n",
        "    StructField(\"rating\", IntegerType(), False),\n",
        "    StructField(\"timestamp\", IntegerType(), False)])\n",
        "\n",
        "schema_items = StructType([\n",
        "    StructField(\"item_id\", IntegerType(), False),\n",
        "    StructField(\"movie\", StringType(), False)])\n",
        "\n",
        "training = spark.read.option(\"sep\", \"\\t\").csv(\"MovieLens.training\", header=False, schema=schema_ratings)\n",
        "test = spark.read.option(\"sep\", \"\\t\").csv(\"MovieLens.test\", header=False, schema=schema_ratings)\n",
        "items = spark.read.option(\"sep\", \"|\").csv(\"MovieLens.item\", header=False, schema=schema_items)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MC_m1oygCoEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10c9c8a7-dea3-4ed6-c0a3-2594ba9a40be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- item_id: integer (nullable = true)\n",
            " |-- rating: integer (nullable = true)\n",
            " |-- timestamp: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81Vgo4ovCqtQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdc9236d-b54a-4ee8-c26e-ea9ce9d1c9a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- item_id: integer (nullable = true)\n",
            " |-- movie: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "items.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRaF2A_j_nC7"
      },
      "source": [
        "### Your task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM9w2aUvJ7KN"
      },
      "source": [
        "Let's compute some stats!  What is the number of ratings in the training and test dataset? How many movies are in our dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XZaH16t_CIw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0e54f93-334b-445e-b3ee-ebb184817aff",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of ratings in the training dataset: 80000\n",
            "Number of ratings in the test dataset: 20000\n",
            "Number of movies in the dataset: 1682\n"
          ]
        }
      ],
      "source": [
        "# Compute the number of ratings in the training and test dataset.\n",
        "training_count = training.count()\n",
        "test_count = test.count()\n",
        "\n",
        "print(f\"Number of ratings in the training dataset: {training_count}\")\n",
        "print(f\"Number of ratings in the test dataset: {test_count}\")\n",
        "\n",
        "# Compute the number of movies in the dataset\n",
        "movie_count = items.select(\"item_id\").distinct().count()\n",
        "\n",
        "print(f\"Number of movies in the dataset: {movie_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpsaYOqRxar2"
      },
      "source": [
        "Using the training set, train a model with the Alternating Least Squares method available in the Spark MLlib: [https://spark.apache.org/docs/latest/ml-collaborative-filtering.html](https://spark.apache.org/docs/latest/ml-collaborative-filtering.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oitav_xhQD9w"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.sql import Row\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder.appName(\"ALSExample\").getOrCreate()\n",
        "\n",
        "# Load data\n",
        "lines = spark.read.text(\"/content/MovieLens.training\").rdd\n",
        "# parts = lines.map(lambda row: row.value.split(\"::\"))\n",
        "# ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),\n",
        "#                                      rating=float(p[2]), timestamp=int(p[3])))\n",
        "\n",
        "parts = lines.map(lambda row: row.value.split(\"\\t\"))\n",
        "ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),\n",
        "                                     rating=float(p[2]), timestamp=int(p[3])))\n",
        "\n",
        "ratings = spark.createDataFrame(ratingsRDD)\n",
        "\n",
        "(training, test) = ratings.randomSplit([0.8, 0.2])\n",
        "\n",
        "# Build the recommendation model using ALS on the training data\n",
        "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
        "als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
        "          coldStartStrategy=\"drop\")\n",
        "model = als.fit(training)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtR1xRvonxiO"
      },
      "source": [
        "Now compute the RMSE on the test dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP23Xkgwi0SD",
        "outputId": "22e404a8-6a27-4f7e-b239-b6a78a5db40d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root-mean-square error = 1.121900609777377\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "# Evaluate the model by computing the RMSE on the test data\n",
        "predictions = model.transform(test)\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
        "                                predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root-mean-square error = \" + str(rmse))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBvSaWGEMHXI"
      },
      "source": [
        "At this point, you can use the trained model to produce the top-K recommendations for each user. You have to produce the title of top movies, not just the ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbMlWL5_UfSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b53647e4-8081-4fc6-ed12-6dcd39306c91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------------------------------------------------------+---------+\n",
            "|userId|movie                                                      |rating   |\n",
            "+------+-----------------------------------------------------------+---------+\n",
            "|1     |Angel Baby (1995)                                          |7.623747 |\n",
            "|1     |8 1/2 (1963)                                               |6.129052 |\n",
            "|1     |Safe (1995)                                                |5.9240837|\n",
            "|1     |Mina Tannenbaum (1994)                                     |5.91947  |\n",
            "|1     |Orlando (1993)                                             |5.850461 |\n",
            "|1     |Paradise Lost: The Child Murders at Robin Hood Hills (1996)|5.8177156|\n",
            "|1     |Three Caballeros, The (1945)                               |5.7579355|\n",
            "|1     |Shall We Dance? (1937)                                     |5.72886  |\n",
            "|1     |Dead Man (1995)                                            |5.610992 |\n",
            "|1     |Farewell My Concubine (1993)                               |5.6006866|\n",
            "|3     |Ma vie en rose (My Life in Pink) (1997)                    |10.062742|\n",
            "|3     |Live Nude Girls (1995)                                     |9.998766 |\n",
            "|3     |Ruby in Paradise (1993)                                    |9.092814 |\n",
            "|3     |Hurricane Streets (1998)                                   |8.938976 |\n",
            "|3     |Stupids, The (1996)                                        |8.920418 |\n",
            "|3     |Inventing the Abbotts (1997)                               |8.629754 |\n",
            "|3     |Carpool (1996)                                             |7.796974 |\n",
            "|3     |Browning Version, The (1994)                               |7.5150356|\n",
            "|3     |Flipper (1996)                                             |7.485543 |\n",
            "|3     |Once Were Warriors (1994)                                  |7.1147237|\n",
            "+------+-----------------------------------------------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "# Produce the top-K recommendations for each user\n",
        "topK = 10\n",
        "userRecs = model.recommendForAllUsers(topK)\n",
        "\n",
        "# Join with the items dataframe to get movie titles\n",
        "userRecs = userRecs.withColumn(\"recommendations\", explode(\"recommendations\"))\n",
        "userRecs = userRecs.select(col(\"userId\"), col(\"recommendations.movieId\"), col(\"recommendations.rating\"))\n",
        "\n",
        "# Join with items dataframe to get movie titles\n",
        "userRecsWithTitles = userRecs.join(items, userRecs.movieId == items.item_id).select(\"userId\", \"movie\", \"rating\")\n",
        "\n",
        "# Show the top-K recommendations for each user\n",
        "userRecsWithTitles.show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add your own ratings to the dataset and use the model to produce top-K recommendations for yourself.\n",
        "\n",
        "These are the steps that you need to take:\n",
        "\n",
        "\n",
        "1.   Search the dataset for movies that you have watched before. You need the ids of those movies\n",
        "2.   Add your ratings to the training dataset. You need to generate a unique user_id for yourself (a user_id that does not already exist in the dataset).\n",
        "3.   Train the model using the new dataset.\n",
        "4.   Produce top-K recommendation for youself.\n",
        "\n"
      ],
      "metadata": {
        "id": "gQvT7_qsB2QA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "\n",
        "# 1. Search the dataset for movies that you have watched before. You need the ids of those movies\n",
        "watched_movies = [\"Toy Story (1995)\", \"GoldenEye (1995)\", \"Four Rooms (1995)\"]\n",
        "watched_movies_ids = items.filter(items.movie.isin(watched_movies)).select(\"item_id\", \"movie\").collect()\n",
        "print(\"Watched movies and their IDs:\")\n",
        "for row in watched_movies_ids:\n",
        "    print(f\"{row['movie']}: {row['item_id']}\")\n",
        "\n",
        "# 2. You need to generate a unique user_id for yourself (a user_id that does not already exist in the dataset)\n",
        "my_user_id = 9999\n",
        "\n",
        "# 2. Add your ratings to the training dataset.\n",
        "my_ratings_data = [\n",
        "    (my_user_id, row['item_id'], 5, int(np.datetime64('now').astype(int) // 10**9))  # 假设你给这些电影的评分都是 5\n",
        "    for row in watched_movies_ids\n",
        "]\n",
        "\n",
        "my_ratings_schema = StructType([\n",
        "    StructField(\"user_id\", IntegerType(), False),\n",
        "    StructField(\"item_id\", IntegerType(), False),\n",
        "    StructField(\"rating\", IntegerType(), False),\n",
        "    StructField(\"timestamp\", IntegerType(), False)\n",
        "])\n",
        "\n",
        "my_ratings_df = spark.createDataFrame(my_ratings_data, my_ratings_schema)\n",
        "\n",
        "# 2. Add your ratings to the training dataset.\n",
        "new_training = training.union(my_ratings_df)\n",
        "\n",
        "# 3. Train the model using the new dataset.\n",
        "new_model = als.fit(new_training)\n",
        "\n",
        "# 4. Generate top-K recommendations for yourself\n",
        "topK = 10\n",
        "my_recs = new_model.recommendForUserSubset(spark.createDataFrame([(my_user_id,)], [\"userId\"]), topK)\n",
        "\n",
        "# Join with the items dataframe to get movie titles\n",
        "my_recs = my_recs.withColumn(\"recommendations\", explode(\"recommendations\"))\n",
        "my_recs = my_recs.select(col(\"userId\"), col(\"recommendations.movieId\"), col(\"recommendations.rating\"))\n",
        "\n",
        "# change the column name “movieId” to “item_id” for join\n",
        "my_recs = my_recs.withColumnRenamed(\"movieId\", \"item_id\")\n",
        "\n",
        "# Join with items dataframe to get movie titles\n",
        "my_recs_with_titles = my_recs.join(items, my_recs.item_id == items.item_id).select(\"userId\", \"movie\", \"rating\")\n",
        "\n",
        "# Show the top-K recommendations for yourself\n",
        "my_recs_with_titles.show(truncate=False)\n"
      ],
      "metadata": {
        "id": "POHVCFQbB_I_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd5f4399-8d84-4542-d7a5-0081b6b67649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Watched movies and their IDs:\n",
            "Toy Story (1995): 1\n",
            "GoldenEye (1995): 2\n",
            "Four Rooms (1995): 3\n",
            "+------+--------------------------------------------------------------------+---------+\n",
            "|userId|movie                                                               |rating   |\n",
            "+------+--------------------------------------------------------------------+---------+\n",
            "|9999  |Ruling Class, The (1972)                                            |6.533584 |\n",
            "|9999  |Angel Baby (1995)                                                   |6.477675 |\n",
            "|9999  |Bread and Chocolate (Pane e cioccolata) (1973)                      |6.2941732|\n",
            "|9999  |Haunted World of Edward D. Wood Jr., The (1995)                     |6.2030606|\n",
            "|9999  |Burnt By the Sun (1994)                                             |6.181601 |\n",
            "|9999  |Pather Panchali (1955)                                              |6.102566 |\n",
            "|9999  |Sum of Us, The (1994)                                               |6.0794644|\n",
            "|9999  |Supercop (1992)                                                     |6.0306206|\n",
            "|9999  |Wild Things (1998)                                                  |6.0132227|\n",
            "|9999  |Garden of Finzi-Contini, The (Giardino dei Finzi-Contini, Il) (1970)|5.991159 |\n",
            "+------+--------------------------------------------------------------------+---------+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}